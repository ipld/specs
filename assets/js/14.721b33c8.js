(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{373:function(e,t,a){"use strict";a.r(t);var i=a(44),o=Object(i.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"codecs-and-completeness"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#codecs-and-completeness"}},[e._v("#")]),e._v(" Codecs and Completeness")]),e._v(" "),a("p",[e._v('IPLD has a very all-embracing approach to compatibility: many systems have some sort of bridge to IPLD.\nAs a result, it\'s very important to understand which of those bridges are "complete", and which contain limitations;\nand for those that have limitations, what those limitations are.\nMost of this appears in the Codec layer: because Codecs are responsible for how data is serialized,\nthey encompass almost all of the compatibility efforts in bridging IPLD systems to each other and to other systems.')]),e._v(" "),a("p",[e._v('We define "completeness" in terms of the [[Data Model]] (and split it into two concepts):')]),e._v(" "),a("ol",[a("li",[e._v('A "complete" codec is one that can represent '),a("strong",[e._v("all")]),e._v(" of the IPLD Data Model;")]),e._v(" "),a("li",[e._v('A "fitted" codec is one for any data in the IPLD Data Model, can represent it only precisely '),a("strong",[e._v("one")]),e._v(" way.")])]),e._v(" "),a("p",[e._v('A "complete" AND "fitted" codec is [[bidirectional]].')]),e._v(" "),a("p",[e._v("What about codecs that aren't?")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("complete/incomplete:")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("complete")]),e._v(": contains all of IPLD Data Model")]),e._v(" "),a("li",[a("strong",[e._v("incomplete")]),e._v(' (aka "lossy"): cannot represent some Data Model data...\n'),a("ul",[a("li",[a("strong",[e._v("disordered")]),e._v(": does not preserve map entry order on either encode or decode\n"),a("ul",[a("li",[e._v("n.b., sorting codecs are disordered and therefore lossy!  this isn't purely a bad thing (it means those codecs have a greater tendency towards [[(uncoordinated) convergence]], which can be useful), but it is a thing that's important to note about a codec.")])])]),e._v(" "),a("li",[a("strong",[e._v("underkinded")]),e._v(": does not have ways to clearly disambiguate IPLD Data Model kinds\n"),a("ul",[a("li",[e._v("e.g. if it's impossible to tell apart the number "),a("code",[e._v("1")]),e._v(" and the string "),a("code",[e._v('"1"')]),e._v(", that's an underkinded codec.")]),e._v(" "),a("li",[e._v("e.g. if a format doesn't have a way to encode IPLD Links, that's underkinded.")])])]),e._v(" "),a("li",[a("strong",[e._v("loose-stringed")]),e._v(": does not reliably preserve all strings or byte sequences\n"),a("ul",[a("li",[e._v('e.g. if something does character "normalization" on strings rather than respecting and round-tripping all 8-bit sequences, that\'s loose-stringed.')])])]),e._v(" "),a("li",[a("strong",[e._v("plane-mangling")]),e._v(': does not reliably preserve all strings or byte sequences... because some of them are reserved sentinels for "control" sequences.\n'),a("ul",[a("li",[e._v('"plane-mangling" is sometimes also known as "confusing the control plane and the data plane" (and has many other names as well; it\'s an important and frequently-rediscovered concept).')]),e._v(" "),a("li",[e._v("e.g. if it's illegal for a map to have a key that is the string "),a("code",[e._v('"/"')]),e._v(", that's plane-mangling.")]),e._v(" "),a("li",[e._v('"plane-mangling" and "loose-stringed" are different only by intent, yes -- but we find that identifying the source and approximate impact radius of the issue by naming them separately is useful.')])])]),e._v(" "),a("li",[a("strong",[e._v("skeletoid")]),e._v(": can only accept some very specific structures of data.\n"),a("ul",[a("li",[a("strong",[e._v("skeletoid+parameterized")]),e._v(": some parameters (e.g., more than the multicodec identifier) are needed to be able to morph the data to and from the IPLD Data Model.")]),e._v(" "),a("li",[e._v("(it may be interesting to compare and contrast this to IPLD Schemas!  IPLD Schemas can describe data structurally, but do it in a way that composes "),a("em",[e._v("over")]),e._v(" codecs, rather than being entangled "),a("em",[e._v("in")]),e._v(" codecs and thus limiting their completeness.)")]),e._v(" "),a("li",[e._v('TODO: naming?  alts: "finitestructured"?  other?')])])])])])])]),e._v(" "),a("li",[a("p",[e._v("fitted/illfitted:")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("fitted")]),e._v(": has exactly one way to encode any IPLD Data Model content that it encodes; and, does not have a way to encode things that the IPLD Data Model doesn't describe.")]),e._v(" "),a("li",[a("strong",[e._v("illfitted")]),e._v(": has more than one that some IPLD Data Model content could arguably be encoded; or, can encode "),a("em",[e._v("more")]),e._v(" things things than the IPLD Data Model considers to be distinctive.\n"),a("ul",[a("li",[a("strong",[e._v("baroque")]),e._v(": supports variations in the encoded format which are non-semantic and not preserved in the IPLD Data Model.")]),e._v(" "),a("li",[a("strong",[e._v("topowild")]),e._v(": supports topologically different structures than the IPLD Data Model (in other words, forms of recursion that are neither maps nor lists).\n"),a("ul",[a("li",[e._v('n.b. in many cases a codec can be made non-topowild by simply defining a morphism from these exotic structures onto the IPLD Data Model... but this usually makes them "incomplete(skeletoid)" (and possibly "skeletoid+parameterized") instead... and typically also implies other usability frictions which may or may not be acceptable (think: the depth of tree becomes roughly doubled, because a metadata map wraps around every actual data element.)')])])])])])])])]),e._v(" "),a("p",[e._v("N.b. a codec that has "),a("em",[e._v("normalization")]),e._v(" modes during encoding, but is "),a("em",[e._v("lenient")]),e._v(" during decoding: this is still considered "),a("strong",[e._v("illfitted")]),e._v(".\n(TODO: maybe we want another term to flag this, because lenient modes are common enough to be worth special discussion; but we also need to cover what a worry that is when adjacent to hashing.)")]),e._v(" "),a("h2",{attrs:{id:"examples-of-codecs-and-their-completeness-and-fittedness"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#examples-of-codecs-and-their-completeness-and-fittedness"}},[e._v("#")]),e._v(" Examples of Codecs and their Completeness and Fittedness")]),e._v(" "),a("p",[e._v("(It may be worth reading the [Incompleteness is Valid] section before proceeding,\nor this might look pretty bleak!  Very few things are Complete AND Fitted.)")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("CBOR: is a complete but "),a("em",[e._v("illfitted")]),e._v(" codec!")]),e._v(" "),a("ul",[a("li",[e._v("Complete: The entire data model fits!")]),e._v(" "),a("li",[e._v("Illfitted(baroque): maps and lists have multiple variations: they can be length-prefixed or indeterminate-length encoding.")]),e._v(" "),a("li",[e._v("Illfitted(baroque): maps can contain non-string keys, and indeed even mixed key kinds.")]),e._v(" "),a("li",[e._v("Illfitted(baroque): floats and integers can be encoded in various binary sizes; there's no strict requirement that they use the smallest possible encoding.")]),e._v(" "),a("li",[e._v('Illfitted(topowild): "tags" can be associated with every piece of data (including tags-on-tags); this information does not readily map to the IPLD Data Model.')])])]),e._v(" "),a("li",[a("p",[e._v("DAG-CBOR: is an "),a("em",[e._v("incomplete")]),e._v(" but fitted codec!")]),e._v(" "),a("ul",[a("li",[e._v("Incomplete(disordered): because DAG-CBOR specifies a strict sorting order for map entries, it necessarily discards map entry order information!")]),e._v(" "),a("li",[e._v("More fitted than CBOR alone: DAG-CBOR specifies that maps and lists must use the length-prefixed encoding.")]),e._v(" "),a("li",[e._v("More fitted than CBOR alone: DAG-CBOR specifies that maps must only contain string keys.")]),e._v(" "),a("li",[e._v("More fitted than CBOR alone: DAG-CBOR specifies that floats and integers must be encoded using the smallest possible encoding.")]),e._v(" "),a("li",[e._v("More fitted than CBOR alone: DAG-CBOR specifies that tag 42 (which we use for links) is the only allowed tag.")])])]),e._v(" "),a("li",[a("p",[e._v("JSON: is an "),a("em",[e._v("incomplete")]),e._v(" and "),a("em",[e._v("illfitted")]),e._v(" codec!")]),e._v(" "),a("ul",[a("li",[e._v("Incomplete(underkinded): binary cannot be encoded unambiguously in JSON.  (Base64 is often used when encoding; but one can't tell the difference string and binary to decide whether to b64decode later when decoding.)")]),e._v(" "),a("li",[e._v("Incomplete(underkinded): floats and integers cannot be reliably distinguished in JSON.")]),e._v(" "),a("li",[e._v("Incomplete(underkinded): how to encode IPLD Links in JSON is not defined (although see DAG-JSON).")]),e._v(" "),a("li",[e._v("Illfitted(baroque): non-semantic whitespace can be used freely in JSON.")]),e._v(" "),a("li",[e._v("Illfitted(baroque): strings in JSON can be escaped (or not) in various ways, and parsers will accept variations.  These variations are not roundtripped by most JSON libraries.")])])]),e._v(" "),a("li",[a("p",[e._v("DAG-JSON: is an "),a("em",[e._v("incomplete")]),e._v(" but fitted codec:")]),e._v(" "),a("ul",[a("li",[e._v("Incomplete(disordered): because DAG-JSON specifies a strict sorting order for map entries, it necessarily discards map entry order information!")]),e._v(" "),a("li",[e._v("More complete than JSON alone: DAG-JSON specifies how to encode IPLD Links!  However... see next line:")]),e._v(" "),a("li",[e._v("Incomplete(plane-mangling): because DAG-JSON reserves maps with a single key that is the string "),a("code",[e._v('"/"')]),e._v(" as a sentinel to indicate an IPLD Link, it is "),a("em",[e._v("lossy")]),e._v(": user data which "),a("em",[e._v("happens")]),e._v(" to contain a single map that just happened to have the "),a("code",[e._v('"/"')]),e._v(" character as a key "),a("em",[e._v("cannot be encoded")]),e._v(" in DAG-JSON.")]),e._v(" "),a("li",[e._v("More complete than JSON alone: DAG-JSON specifies how to encode raw binary bytes, and how to detect them unambiguously during decoding.  However... see next line:")]),e._v(" "),a("li",[e._v("Incomplete(plane-mangling): a similar pattern to that for Links is also reserved to indicate binary bytes; this effectively blocks user data from using the same space.")]),e._v(" "),a("li",[e._v("More fitted than JSON alone: DAG-JSON specifies that any non-semantic whitespace must not be used.")])])]),e._v(" "),a("li",[a("p",[e._v("git: is an "),a("em",[e._v("incomplete")]),e._v(" but fitted codec!")]),e._v(" "),a("ul",[a("li",[e._v('Incomplete(skeletoid): Git objects only contain very specific structures: we mostly treat them as if they\'re maps in the Data Model (e.g. a git commit object is treated as a map with a key called "author_name").  It is not possible to encode arbitrary maps into arbitrary git objects, nor put links in arbitrary places, etc.')]),e._v(" "),a("li",[e._v("Fitted: there is "),a("em",[e._v("one way")]),e._v(' to serialize (and hash) any git object.  This is the definition of "fitted".  (All structures have known orders; all maps (such as directories) are defined as sorted order.)')])])]),e._v(" "),a("li",[a("p",[e._v("DAG-PB: is an "),a("em",[e._v("incomplete")]),e._v(" and dubiously fitted codec!")]),e._v(" "),a("ul",[a("li",[e._v("Incomplete(skeletoid): DAG-PB only stores very specific structures of data.\n"),a("ul",[a("li",[e._v("Note: (perhaps surprisingly) DAG-PB is "),a("em",[e._v("not")]),e._v(' "skeletoid+parameterized": it\'s '),a("em",[e._v("just")]),e._v(" skeletoid.  DAG-PB doesn't actually support arbitrary protobufs!  It just supports one very "),a("em",[e._v("specific")]),e._v(" protobuf schema: https://github.com/ipld/specs/blob/master/block-layer/codecs/dag-pb.md#serial-format.")]),e._v(" "),a("li",[e._v("The IPLD Schema describing how we see this data in the IPLD Data Model can be found here: https://github.com/ipld/specs/blob/master/block-layer/codecs/dag-pb.md#logical-format")])])]),e._v(" "),a("li",[e._v("Dubiously fitted: although the DAG-PB spec defines a specific ordering for the serialized ordering of protobuf fields, and mandates that no unknown fields may be included, and this should be sufficient to qualify as fitted... Be aware that most protobuf tools in the wild may not support this strictness, and it may be difficult in practice to produce code which honors these rules.")]),e._v(" "),a("li",[e._v("Other significant issues exist with DAG-PB codecs in practice: some widely used libraries have definitions of pathing (and thus implicitly how the DAG-PB data morphism to the Data Model is defined) which don't match the schema at all.  This document you are reading doesn't even have vocabulary to describe this kind of problem, because we hope that going forward the development of new codecs will be sufficiently standardized that this kind of issue will not emerge again.")])])])]),e._v(" "),a("p",[e._v("Note that it's "),a("em",[e._v("possible")]),e._v(" to implement codecs which regard some of these formats different, and they could have different properties:\nfor example, could could imagine writing a CBOR codec which actually represents every occurrence of a CBOR tag\nas if it was a map in the IPLD Data Model with a single key and value, and encode the tag into a string to use as the key;\nand this would make it less illfitted than the CBOR codec described above during decoding...\nyet at the same time, also make it more incomplete, since it would be unclear how to disambiguate this from "),a("em",[e._v("regular")]),e._v(' maps with single keys,\nand would require inventing some form of escaping, etc...\nIn general, this spirals into "yes, indeed, anything is possible!" Turing-tarpit territory; we will say no more about it.')]),e._v(" "),a("h2",{attrs:{id:"using-the-incompleteness-ontology"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-the-incompleteness-ontology"}},[e._v("#")]),e._v(" Using the Incompleteness Ontology")]),e._v(" "),a("ul",[a("li",[e._v("[Incompleteness is Valid]")]),e._v(" "),a("li",[e._v("[Incompleteness categories are not directly comparable]")]),e._v(" "),a("li",[e._v("[Completeness and fittedness are a tug-of-war]")]),e._v(" "),a("li",[e._v("[Yes, you can work around incompleteness]")])]),e._v(" "),a("h3",{attrs:{id:"incompleteness-is-valid"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#incompleteness-is-valid"}},[e._v("#")]),e._v(" Incompleteness is Valid")]),e._v(" "),a("p",[e._v("Incomplete codecs are perfectly valid!  We have lots of them.  They can accomplish useful work.")]),e._v(" "),a("p",[e._v("Illfitted codecs are perfectly valid!  We have lots of them.  They can accomplish useful work.")]),e._v(" "),a("p",[e._v("The whole world is full of various formats that are either incomplete or illfitted "),a("em",[e._v("even when paired with themselves")]),e._v(' -- for example, YAML is incredible at this:\na staggering number of YAML libraries and parsers regularly forget huge amounts of information about their own AST in normal operation, and thus fail to round-trip documents;\nor, have shocking-to-the-user ambiguities like the infamous "port mappings are sometimes confused with times and parsed in base-60" issue.\nThese formats still persist and are widely used, and '),a("em",[e._v("that's okay")]),e._v(".")]),e._v(" "),a("p",[e._v("It's just important to be aware of it.")]),e._v(" "),a("p",[e._v("Incomplete and illfitted codecs often can even safely round-trip data, "),a("em",[e._v("when using the same codec for decode and encode")]),e._v(".\nIt's only when mix-and-matching them, or transforming or generating new data, that one needs to really watch out.")]),e._v(" "),a("p",[e._v("All of our efforts in documenting incompleteness, illfittedness, and categorizing specific kinds of it is in the interest of improving IPLD documentation,\nand making sure our community can use systems while understanding what they promise (and what they don't).\nIt's not meant to cast shade on systems that have these markers.")]),e._v(" "),a("h3",{attrs:{id:"incompleteness-categories-are-not-directly-comparable"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#incompleteness-categories-are-not-directly-comparable"}},[e._v("#")]),e._v(" Incompleteness categories are not directly comparable")]),e._v(" "),a("p",[e._v("Incompleteness categories are not directly comparable;\nit's necessary to examine the details of a case to know if data from one codec can be transcoded into another codec without fear of loss or domain range errors.")]),e._v(" "),a("p",[e._v("By example: if two codecs are both plane-mangling, but\none of them has special behaviors that make map keys starting with "),a("code",[e._v('"__"')]),e._v(" illegal for user data,\nwhile the other says map keys containing the "),a("code",[e._v('"/"')]),e._v(" character are illegal...\nthen their incompleteness doesn't balance each other out!\nYou will still have the possibility of data which is encodable in one codec,\nbut which cannot be transcoded to the other!")]),e._v(" "),a("p",[e._v("On the other hand: two codecs can both be incomplete in different ways, but compose just fine together:\nfor example, data produced by a git codec decoding some serial data can be easily transcoded into a dag-cbor codec, and this is definitely safe.\n(That data in a dag-cbor encoding can also be understood to be transcodeable back to a git codec,\nif we know that the domain of the data hasn't changed to include some data outside of the domain that the git codec handles.)\nThe converse of this example, starting with any arbitrary dag-cbor data, is back to untrue:\nthe dag-cbor codec, though incomplete, still has wider domain of encodable values than the git codec does.")]),e._v(" "),a("h3",{attrs:{id:"completeness-and-fittedness-are-a-tug-of-war"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#completeness-and-fittedness-are-a-tug-of-war"}},[e._v("#")]),e._v(" Completeness and fittedness are a tug-of-war")]),e._v(" "),a("p",[e._v("Almost "),a("em",[e._v("every")]),e._v(" codec will be either incomplete or illfitted,\nunless it was designed from scratch specifically to be isomorphic to the IPLD Data Model.")]),e._v(" "),a("p",[e._v("Formats that are more expressive than the Data Model are naturally illfitted.")]),e._v(" "),a("p",[e._v("Formats that are less expressive than the Data Model are naturally incomplete.")]),e._v(" "),a("p",[e._v("Moving in "),a("em",[e._v("any")]),e._v(" direction other than staying exactly isomorphic to the IPLD Data Model means becoming one or the other.")]),e._v(" "),a("p",[e._v("It's not a strictly one-dimensional tug-of-war either:\na codec can readily be "),a("em",[e._v("neither")]),e._v(" complete "),a("em",[e._v("nor")]),e._v(" fitted.")]),e._v(" "),a("p",[e._v("This is "),a("em",[e._v("okay")]),e._v(" -- see [Incompleteness is Valid] -- it's just important to be aware of the limitations of the codecs you use.")]),e._v(" "),a("h3",{attrs:{id:"yes-you-can-work-around-incompleteness"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#yes-you-can-work-around-incompleteness"}},[e._v("#")]),e._v(" Yes, you can work around incompleteness")]),e._v(" "),a("p",[e._v('Many applications in practice use tactics like the base64-for-raw-bytes approach for JSON.\nObviously, this "works"... so why can\'t we just use that in IPLD?')]),e._v(" "),a("p",[e._v('Well, because it only "works" when presuming some conditions that we '),a("em",[e._v("don't")]),e._v(" accept presumption of in IPLD.\nWhen other applications do this, they're relying on some "),a("em",[e._v("application level knowledge")]),e._v(" about where the raw-bytes data is in a structure.\nThis additional understanding of the structure of the data floats around out-of-band, implicitly:\nit's knowledge like \"the 'foobar' key in the map inside the top level list?  Yeah, that field should be b64decode'd\".")]),e._v(" "),a("p",[a("em",[e._v("We don't have implicit knowledge like that")]),e._v(" in IPLD.\nBecause we have a clear layering model -- Codecs must transform raw serialized data into recognizable IPLD Data Model --\nthe Codec has to decide "),a("em",[e._v("what [[Kind]]")]),e._v(" the data is, and they have to do this "),a("em",[e._v("at the Codec level")]),e._v(" -- which means "),a("em",[e._v("without")]),e._v(" application-level logic.")]),e._v(" "),a("p",[e._v('(Unless they\'re a parameterized+skeletoid codec which has more-than-multicodec levels of configuration.\nThen those codecs can have that kind of knowledge, of course.\nBut we still call those "illfitted", specifically because requiring that kind of configuration breaks the layer models in ways that are important to notice and advisable to avoid.)')])])}),[],!1,null,null,null);t.default=o.exports}}]);