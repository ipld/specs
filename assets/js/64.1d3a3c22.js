(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{423:function(t,e,a){"use strict";a.r(e);var s=a(45),n=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"root-type-definitions-for-adl-schema-declarations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#root-type-definitions-for-adl-schema-declarations"}},[t._v("#")]),t._v(" Root type definitions for ADL schema declarations")]),t._v(" "),a("p",[t._v("This text formed an original part of https://github.com/ipld/specs/pull/182 for the file schemas/advanced-layouts.md. The initial proposal included a "),a("code",[t._v("root")]),t._v(" type specifier for "),a("code",[t._v("advanced")]),t._v(" declarations that would allow the schema parser to make assumptions (and assertions) about the data found at the node where the ADL was encountered.")]),t._v(" "),a("p",[t._v("This (partly) necessitated the connection of an ADL implementation schema to an ADL usage schema, such that a user would have to reach into the implementation and refer to a type defined there. For this reason (primarily), "),a("code",[t._v("root")]),t._v(" was removed from the proposal and an ADL is to be declared simply with its name, "),a("code",[t._v("advanced Foo")]),t._v(", and no additional information, for now.")]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"root-node-type-definitions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#root-node-type-definitions"}},[t._v("#")]),t._v(" Root node type definitions")]),t._v(" "),a("p",[t._v("Advanced layouts are designed to abstract data that exists at the data model layer. As such, they may also dictate what they expect from the data that exists at the node their "),a("em",[t._v("root")]),t._v(" resides at.")]),t._v(" "),a("p",[t._v("In the case of our "),a("code",[t._v("ROT13")]),t._v(" "),a("code",[t._v("string")]),t._v(" representation, we are likely to want to store this on the block as a "),a("code",[t._v("string")]),t._v(" (i.e. this is a crude encryption mechanism, transforming "),a("code",[t._v("string")]),t._v(" to "),a("code",[t._v("string")]),t._v("â€”realistic encryption mechanisms are likely to involve "),a("code",[t._v("bytes")]),t._v(" and perhaps complex data structures to store encryption metadata).")]),t._v(" "),a("div",{staticClass:"language-ipldsch extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ipldsch"}},[a("code",[a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("advanced")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ROT13")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  root String\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MyString")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("string")]),t._v(" representation ROT13\n\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Name")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  firstname MyString\n  surname MyString\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("A validator using our schema is now able to assert that it should find a "),a("code",[t._v("map")]),t._v(" (default "),a("code",[t._v("struct")]),t._v(" representation) with two fields, "),a("code",[t._v("firstname")]),t._v(" and "),a("code",[t._v("surname")]),t._v(", and, thanks to the "),a("code",[t._v("root")]),t._v(" definition of "),a("code",[t._v("ROT13")]),t._v(", it may also assert that these two fields are of kind "),a("code",[t._v("string")]),t._v(".")]),t._v(" "),a("p",[t._v("We may also introduce complex types as the root definition. For example, a "),a("code",[t._v("byte")]),t._v(" representation that is a chain of blocks, each containing a section of "),a("code",[t._v("bytes")]),t._v(" and a link to the next block:")]),t._v(" "),a("div",{staticClass:"language-ipldsch extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ipldsch"}},[a("code",[a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("advanced")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ChainedBytes")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  root Chunk\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Chunk")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  contents Bytes\n  next "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("nullable")]),t._v(" Link\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("Or, as in the IPLD "),a("RouterLink",{attrs:{to:"/design/history/data-structures/hashmap.html"}},[t._v("HashMap")]),t._v(" spec:")],1),t._v(" "),a("div",{staticClass:"language-ipldsch extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ipldsch"}},[a("code",[a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("advanced")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  root HashMapRoot\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Root node layout")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMapRoot")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  hashAlg String\n  bucketSize Int\n  map Bytes\n  data "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" Element "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ... `Element` (and further) definition omitted")]),t._v("\n")])])]),a("p",[t._v("And we could use this to define a map of "),a("code",[t._v("string")]),t._v("s to "),a("code",[t._v("link")]),t._v("s:")]),t._v(" "),a("div",{staticClass:"language-ipldsch extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ipldsch"}},[a("code",[a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MyMap")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" String "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Link "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" representation HashMap\n")])])]),a("p",[t._v("We could even combine usage of our "),a("code",[t._v("ROT13")]),t._v(" and "),a("code",[t._v("HashMap")]),t._v(" definitions in novel ways:")]),t._v(" "),a("div",{staticClass:"language-ipldsch extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ipldsch"}},[a("code",[a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BigConfidentialCatalog")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" Secretz "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Secretz")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("struct")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  title MyString\n  data MyMap\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token typedef"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MyMap")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" String "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Name "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" representation HashMap\n")])])]),a("p",[t._v("If we were to take an IPLD node, and assert that it is of type "),a("code",[t._v("BigConfidentialCatalog")]),t._v(", we should expect that:")]),t._v(" "),a("ol",[a("li",[t._v("The node is a "),a("code",[t._v("list")]),t._v(" kind")]),t._v(" "),a("li",[t._v("Each element of the "),a("code",[t._v("list")]),t._v(" contains a "),a("code",[t._v("map")]),t._v(", which is described by "),a("code",[t._v("Secretz")])]),t._v(" "),a("li",[t._v("Each map contains the two properties defined by "),a("code",[t._v("Secretz")]),t._v(": "),a("code",[t._v("title")]),t._v(" and "),a("code",[t._v("data")])]),t._v(" "),a("li",[t._v("The "),a("code",[t._v("title")]),t._v(" property of the "),a("code",[t._v("map")]),t._v(" is of "),a("code",[t._v("string")]),t._v(" kind, thanks to the "),a("code",[t._v("MyString")]),t._v(" definition, but it must be transformed through the "),a("code",[t._v("ROT13")]),t._v(" layout to make sense of it.")]),t._v(" "),a("li",[t._v("The "),a("code",[t._v("data")]),t._v(" property of the "),a("code",[t._v("map")]),t._v(" is of "),a("code",[t._v("map")]),t._v(" kind, which itself should conform to the "),a("code",[t._v("HashMapRoot")]),t._v(" type specification, but must be interacted through with the logic associated with "),a("code",[t._v("HashMap")]),t._v(" in order to make sense of it (which may also involve loading further blocks to traverse the sharded data).")])]),t._v(" "),a("p",[t._v("If "),a("code",[t._v("ROT13")]),t._v(" and "),a("code",[t._v("HashMap")]),t._v(" were to omit their "),a("code",[t._v("root")]),t._v(" descriptor, we could only make assertions 1 and 2 above.")])])}),[],!1,null,null,null);e.default=n.exports}}]);